---
---
@article{team2025kimi,
  title={Kimi-vl technical report},
  author={Team, Kimi and Du, Angang and Yin, Bohong and Xing, Bowei and Qu, Bowen and Wang, Bowen and Chen, Cheng and Zhang, Chenlin and Du, Chenzhuang and Wei, Chu and others},
  journal={arXiv preprint arXiv:2504.07491},
  year={2025}
}

@article{hao2024llm,
  title={LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models},
  author={Hao, Shibo and Gu, Yi and Luo, Haotian and Liu, Tianyang and Shao, Xiyan and Wang, Xinyuan and Xie, Shuhua and Ma, Haodi and Samavedhi, Adithya and Gao, Qiyue and others},
  journal={arXiv preprint arXiv:2404.05221},
  year={2024},
  code={https://github.com/maitrix-org/llm-reasoners},
  pdf={https://arxiv.org/pdf/2404.05221},
  abstract={Generating accurate step-by-step reasoning is essential for Large Language Models (LLMs) to address complex problems and enhance robustness and interpretability. Despite the flux of research on developing advanced reasoning approaches, systematically analyzing the diverse LLMs and reasoning strategies in generating reasoning chains remains a significant challenge. The difficulties stem from the lack of two key elements: (1) an automatic method for evaluating the generated reasoning chains on different tasks, and (2) a unified formalism and implementation of the diverse reasoning approaches for systematic comparison. This paper aims to close the gap: (1) We introduce AutoRace for fully automated reasoning chain evaluation. Existing metrics rely on expensive human annotations or pre-defined LLM prompts not adaptable to different tasks. In contrast, AutoRace automatically creates detailed evaluation criteria tailored for each task, and uses GPT-4 for accurate evaluation following the criteria. (2) We develop LLM Reasoners, a library for standardized modular implementation of existing and new reasoning algorithms, under a unified formulation of the search, reward, and world model components. With the new evaluation and library, (3) we conduct extensive study of different reasoning approaches (e.g., CoT, ToT, RAP). The analysis reveals interesting findings about different factors contributing to reasoning, including the reward-guidance, breadth-vs-depth in search, world model, and prompt formats, etc.},
  preview={llm_reasoners_preview.png}
}

@article{wang2023promptagent,
  title={PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization},
  author={Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting},
  journal={[ICLR 2024] The Twelfth International Conference on Learning Representations},
  year={2024},
  pdf={https://arxiv.org/pdf/2310.16427.pdf},
  code={https://github.com/XinyuanWangCS/PromptAgent},
  poster={promptagnet_poster_2023.pdf},
  preview={promptagent_header.png},
  abstract={Highly effective, task-specific prompts are often heavily engineered by experts to integrate detailed instructions and domain insights based on a deep understanding of both instincts of large language models (LLMs) and the intricacies of the target task. However, automating the generation of such expert-level prompts remains elusive. Existing prompt optimization methods tend to overlook the depth of domain knowledge and struggle to efficiently explore the vast space of expert-level prompts. Addressing this, we present PromptAgent, an optimization method that autonomously crafts prompts equivalent in quality to those handcrafted by experts. At its core, PromptAgent views prompt optimization as a strategic planning problem and employs a principled planning algorithm, rooted in Monte Carlo tree search, to strategically navigate the expert-level prompt space. Inspired by human-like trial-and-error exploration, PromptAgent induces precise expert-level insights and in-depth instructions by reflecting on model errors and generating constructive error feedback. Such a novel framework allows the agent to iteratively examine intermediate prompts (states), refine them based on error feedbacks (actions), simulate future rewards, and search for high-reward paths leading to expert prompts. We apply PromptAgent to 12 tasks spanning three practical domains: BIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing it significantly outperforms strong Chain-of-Thought and recent prompt optimization baselines. Extensive analyses emphasize its capability to craft expert-level, detailed, and domain-insightful prompts with great efficiency and generalizability.},
}

@INPROCEEDINGS{9696145,
  author={Wang, Xinyuan and Tao, Make and Wang, Runpu and Zhang, Likui},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Reduce the medical burden: An automatic medical triage system using text classification BERT based on Transformer structure}, 
  year={2021},
  pages={679-685},
  doi={10.1109/ICBASE53849.2021.00133},
  pdf={https://ieeexplore.ieee.org/document/9696145},
  abstract={To reduce the pressure of medical triage in the hospitals, this paper proposes a medical triage system that could classify patients' questions or texts about their symptoms into several given categories to give suggestions on which kind of consulting room patients could choose. First, we have done extensive research on the medical care situation and the hospitals' problems in China and conclude that reducing the triage pressure is of great importance for hospitals. We then collect the medical Question Answering datasets, including questions and answers with symptom tags. According to the form of our data, we use BERT, a mainstream model in Natural Language Processing, as the base of our system and modify it with additional components specified to our task. We developed two models based on different datasets. One is trained by data from the five most frequent symptom tags. And for the other one, we use the whole dataset by identifying the appearance of special words, measuring the overlap of all the tags, and merging them into 20 categories. Both of them utilize several training techniques and result in relatively high accuracy: top1 85% accuracy and top2 accuracy 96% on the smaller dataset, top1 accuracy 66.2%, and top2 accuracy 78.3% on the other one. Then we analyze the results and build up our web system for medical use. If given real-world data with similar data distribution, our system could help patients judge diseases and alleviate the triage problem in medical treatment to a certain extent. Moreover, a similar strategy of our model could also be adapted for use in different fields like book searching in libraries. Therefore, our system has a broad application prospect.},
  preview={medicalbert.png}}

@inproceedings{10.1145/3430036.3430068,
  author = {Zhou, Fangfang and Chen, Qi'an and Cui, Yunlong and Wang, Xinyuan and Ma, Hongxu and Zhao, Ying and Li, Xiaoli},
  title = {A Fast Method for Detecting Minority Structures in a Graph},
  year = {2020},
  isbn = {9781450387507},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3430036.3430068},
  doi = {10.1145/3430036.3430068},
  abstract = {A graph contains plentiful structures. Some minority structures are important, such as high degree nodes and bridges. Detecting these minority structures is beneficial to accelerate computational graph analysis and improve the comprehension of graph visualization. Regarding four typical minority structures, this paper proposes two algorithms to detect these structures fast and efficiently. A set of experiments demonstrate the effectiveness of the proposed algorithms.},
  booktitle = {Proceedings of the 13th International Symposium on Visual Information Communication and Interaction},
  articleno = {26},
  numpages = {2},
  keywords = {graph sampling, graph anomaly detection, graph visualization},
  location = {Eindhoven, Netherlands},
  series = {VINCI '20},
  preview={fastmethod.png},
  pdf={https://dl.acm.org/doi/10.1145/3430036.3430068}
}



